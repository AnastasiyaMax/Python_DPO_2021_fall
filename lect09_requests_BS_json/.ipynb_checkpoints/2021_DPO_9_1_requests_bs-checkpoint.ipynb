{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг, практика\n",
    "\n",
    "*Анастасия Паршина, НИУ ВШЭ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Дана ссылка на сайт [IMDb](https://www.imdb.com/calendar/?ref_=nv_mv_cal). Сохраните название и ссылки всех фильмов на странице. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.imdb.com/calendar/?ref_=nv_mv_cal\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/calendar/?ref_=nv_mv_cal'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(url)\n",
    "page.status_code # 200 - все хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4>19 October 2021</h4>,\n",
       " <h4>22 October 2021</h4>,\n",
       " <h4>29 October 2021</h4>,\n",
       " <h4>03 November 2021</h4>,\n",
       " <h4>05 November 2021</h4>,\n",
       " <h4>10 November 2021</h4>,\n",
       " <h4>12 November 2021</h4>,\n",
       " <h4>19 November 2021</h4>,\n",
       " <h4>24 November 2021</h4>,\n",
       " <h4>26 November 2021</h4>,\n",
       " <h4>03 December 2021</h4>,\n",
       " <h4>10 December 2021</h4>,\n",
       " <h4>17 December 2021</h4>,\n",
       " <h4>22 December 2021</h4>,\n",
       " <h4>25 December 2021</h4>,\n",
       " <h4>07 January 2022</h4>,\n",
       " <h4>14 January 2022</h4>,\n",
       " <h4>21 January 2022</h4>,\n",
       " <h4>28 January 2022</h4>,\n",
       " <h4>04 February 2022</h4>,\n",
       " <h4>11 February 2022</h4>,\n",
       " <h4>18 February 2022</h4>,\n",
       " <h4>04 March 2022</h4>,\n",
       " <h4>11 March 2022</h4>,\n",
       " <h4>18 March 2022</h4>,\n",
       " <h4>25 March 2022</h4>,\n",
       " <h4>08 April 2022</h4>,\n",
       " <h4>15 April 2022</h4>,\n",
       " <h4>22 April 2022</h4>,\n",
       " <h4>06 May 2022</h4>,\n",
       " <h4>20 May 2022</h4>,\n",
       " <h4>22 May 2022</h4>,\n",
       " <h4>27 May 2022</h4>,\n",
       " <h4>03 June 2022</h4>,\n",
       " <h4>10 June 2022</h4>,\n",
       " <h4>17 June 2022</h4>,\n",
       " <h4>24 June 2022</h4>,\n",
       " <h4>01 July 2022</h4>,\n",
       " <h4>08 July 2022</h4>,\n",
       " <h4>22 July 2022</h4>,\n",
       " <h4>29 July 2022</h4>,\n",
       " <h4>03 August 2022</h4>,\n",
       " <h4>12 August 2022</h4>,\n",
       " <h4>26 August 2022</h4>,\n",
       " <h4>09 September 2022</h4>,\n",
       " <h4>23 September 2022</h4>,\n",
       " <h4>30 September 2022</h4>,\n",
       " <h4>07 October 2022</h4>,\n",
       " <h4>14 October 2022</h4>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = soup.find_all('h4') # все наши даты\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19 October 2021'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h4')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/title/tt12335692/?ref_=rlm\">Last Man Down</a>,\n",
       " <a href=\"/title/tt1160419/?ref_=rlm\">Dune</a>,\n",
       " <a href=\"/title/tt8847712/?ref_=rlm\">The French Dispatch</a>,\n",
       " <a href=\"/title/tt7504818/?ref_=rlm\">Ron's Gone Wrong</a>,\n",
       " <a href=\"/title/tt8956324/?ref_=rlm\">Warning</a>,\n",
       " <a href=\"/title/tt9639470/?ref_=rlm\">Last Night in Soho</a>,\n",
       " <a href=\"/title/tt7740510/?ref_=rlm\">Antlers</a>,\n",
       " <a href=\"/title/tt13544716/?ref_=rlm\">My Hero Academia: World Heroes' Mission</a>,\n",
       " <a href=\"/title/tt10925852/?ref_=rlm\">A Mouthful of Air</a>,\n",
       " <a href=\"/title/tt6992978/?ref_=rlm\">The Souvenir: Part II</a>,\n",
       " <a href=\"/title/tt9274670/?ref_=rlm\">13 Minutes</a>,\n",
       " <a href=\"/title/tt8400856/?ref_=rlm\">The Grand Duke of Corsica</a>,\n",
       " <a href=\"/title/tt9032400/?ref_=rlm\">Eternals</a>,\n",
       " <a href=\"/title/tt12536294/?ref_=rlm\">Spencer</a>,\n",
       " <a href=\"/title/tt11388416/?ref_=rlm\">Ida Red</a>,\n",
       " <a href=\"/title/tt6852672/?ref_=rlm\">Violet</a>,\n",
       " <a href=\"/title/tt11738830/?ref_=rlm\">The Beta Test</a>,\n",
       " <a href=\"/title/tt3876910/?ref_=rlm\">Dangerous</a>,\n",
       " <a href=\"/title/tt2397461/?ref_=rlm\">Clifford the Big Red Dog</a>,\n",
       " <a href=\"/title/tt12789558/?ref_=rlm\">Belfast</a>,\n",
       " <a href=\"/title/tt9568230/?ref_=rlm\">Night Raiders</a>,\n",
       " <a href=\"/title/tt13265876/?ref_=rlm\">Apex</a>,\n",
       " <a href=\"/title/tt4513678/?ref_=rlm\">Ghostbusters: Afterlife</a>,\n",
       " <a href=\"/title/tt9620288/?ref_=rlm\">King Richard</a>,\n",
       " <a href=\"/title/tt10986222/?ref_=rlm\">C'mon C'mon</a>,\n",
       " <a href=\"/title/tt14033502/?ref_=rlm\">Bad Luck Banging or Loony Porn</a>,\n",
       " <a href=\"/title/tt12229370/?ref_=rlm\">Mothering Sunday</a>,\n",
       " <a href=\"/title/tt14405338/?ref_=rlm\">A House on the Bayou</a>,\n",
       " <a href=\"/title/tt6920084/?ref_=rlm\">Resident Evil: Welcome to Raccoon City</a>,\n",
       " <a href=\"/title/tt11214590/?ref_=rlm\">House of Gucci</a>,\n",
       " <a href=\"/title/tt2953050/?ref_=rlm\">Encanto</a>,\n",
       " <a href=\"/title/tt14039582/?ref_=rlm\">Drive My Car</a>,\n",
       " <a href=\"/title/tt10023286/?ref_=rlm\">The Humans</a>,\n",
       " <a href=\"/title/tt11271038/?ref_=rlm\">Licorice Pizza</a>,\n",
       " <a href=\"/title/tt10698174/?ref_=rlm\">Wolf</a>,\n",
       " <a href=\"/title/tt13453006/?ref_=rlm\">Red Rocket</a>,\n",
       " <a href=\"/title/tt3581652/?ref_=rlm\">West Side Story</a>,\n",
       " <a href=\"/title/tt9714030/?ref_=rlm\">France</a>,\n",
       " <a href=\"/title/tt12800524/?ref_=rlm\">Encounter</a>,\n",
       " <a href=\"/title/tt10872600/?ref_=rlm\">Spider-Man: No Way Home</a>,\n",
       " <a href=\"/title/tt7740496/?ref_=rlm\">Nightmare Alley</a>,\n",
       " <a href=\"/title/tt10832274/?ref_=rlm\">Swan Song</a>,\n",
       " <a href=\"/title/tt10838180/?ref_=rlm\">The Matrix Resurrections</a>,\n",
       " <a href=\"/title/tt6856242/?ref_=rlm\">The King's Man</a>,\n",
       " <a href=\"/title/tt6467266/?ref_=rlm\">Sing 2</a>,\n",
       " <a href=\"/title/tt0995854/?ref_=rlm\">A Journal for Jordan</a>,\n",
       " <a href=\"/title/tt10095582/?ref_=rlm\">The Tragedy of Macbeth</a>,\n",
       " <a href=\"/title/tt11729298/?ref_=rlm\">American Underdog</a>,\n",
       " <a href=\"/title/tt8356942/?ref_=rlm\">The 355</a>,\n",
       " <a href=\"/title/tt11245972/?ref_=rlm\">Scream</a>,\n",
       " <a href=\"/title/tt11671006/?ref_=rlm\">The Man from Toronto</a>,\n",
       " <a href=\"/title/tt2180339/?ref_=rlm\">Deep Water</a>,\n",
       " <a href=\"/title/tt2224162/?ref_=rlm\">Sesame Street</a>,\n",
       " <a href=\"/title/tt7985704/?ref_=rlm\">Operation Fortune: Ruse de guerre</a>,\n",
       " <a href=\"/title/tt5108870/?ref_=rlm\">Morbius</a>,\n",
       " <a href=\"/title/tt7144666/?ref_=rlm\">The Black Phone</a>,\n",
       " <a href=\"/title/tt5834426/?ref_=rlm\">Moonfall</a>,\n",
       " <a href=\"/title/tt11466222/?ref_=rlm\">Jackass Forever</a>,\n",
       " <a href=\"/title/tt7657566/?ref_=rlm\">Death on the Nile</a>,\n",
       " <a href=\"/title/tt10223460/?ref_=rlm\">Marry Me</a>,\n",
       " <a href=\"/title/tt1464335/?ref_=rlm\">Uncharted</a>,\n",
       " <a href=\"/title/tt4998632/?ref_=rlm\">Ambulance</a>,\n",
       " <a href=\"/title/tt11252248/?ref_=rlm\">Dog</a>,\n",
       " <a href=\"/title/tt8337158/?ref_=rlm\">Rumble</a>,\n",
       " <a href=\"/title/tt10503736/?ref_=rlm\">The Ghosts of Borley Rectory</a>,\n",
       " <a href=\"/title/tt1877830/?ref_=rlm\">The Batman</a>,\n",
       " <a href=\"/title/tt8097030/?ref_=rlm\">Turning Red</a>,\n",
       " <a href=\"/title/tt11703710/?ref_=rlm\">Downton Abbey: A New Era</a>,\n",
       " <a href=\"/title/tt9419884/?ref_=rlm\">Doctor Strange in the Multiverse of Madness</a>,\n",
       " <a href=\"/title/tt11138512/?ref_=rlm\">The Northman</a>,\n",
       " <a href=\"/title/tt12593682/?ref_=rlm\">Bullet Train</a>,\n",
       " <a href=\"/title/tt12412888/?ref_=rlm\">Sonic the Hedgehog 2</a>,\n",
       " <a href=\"/title/tt4123432/?ref_=rlm\">Fantastic Beasts: The Secrets of Dumbledore</a>,\n",
       " <a href=\"/title/tt13320622/?ref_=rlm\">Lost City of D</a>,\n",
       " <a href=\"/title/tt11291274/?ref_=rlm\">The Unbearable Weight of Massive Talent</a>,\n",
       " <a href=\"/title/tt8115900/?ref_=rlm\">The Bad Guys</a>,\n",
       " <a href=\"/title/tt10648342/?ref_=rlm\">Thor: Love and Thunder</a>,\n",
       " <a href=\"/title/tt8509238/?ref_=rlm\">Legally Blonde 3</a>,\n",
       " <a href=\"/title/tt8912936/?ref_=rlm\">DC League of Super-Pets</a>,\n",
       " <a href=\"/title/tt1745960/?ref_=rlm\">Top Gun: Maverick</a>,\n",
       " <a href=\"/title/tt10366206/?ref_=rlm\">John Wick: Chapter 4</a>,\n",
       " <a href=\"/title/tt3704428/?ref_=rlm\">Untitled Elvis Presley Project</a>,\n",
       " <a href=\"/title/tt8041270/?ref_=rlm\">Jurassic World: Dominion</a>,\n",
       " <a href=\"/title/tt10298810/?ref_=rlm\">Lightyear</a>,\n",
       " <a href=\"/title/tt5090568/?ref_=rlm\">Transformers: Rise of the Beasts</a>,\n",
       " <a href=\"/title/tt9411972/?ref_=rlm\">Where the Crawdads Sing</a>,\n",
       " <a href=\"/title/tt5113044/?ref_=rlm\">Minions: The Rise of Gru</a>,\n",
       " <a href=\"/title/tt9114286/?ref_=rlm\">Black Panther: Wakanda Forever</a>,\n",
       " <a href=\"/title/tt10954984/?ref_=rlm\">Nope</a>,\n",
       " <a href=\"/title/tt1462764/?ref_=rlm\">Indiana Jones 5</a>,\n",
       " <a href=\"/title/tt6443346/?ref_=rlm\">Black Adam</a>,\n",
       " <a href=\"/title/tt13917358/?ref_=rlm\">Guns 3: Alias Billy the Kid</a>,\n",
       " <a href=\"/title/tt9731598/?ref_=rlm\">BROS</a>,\n",
       " <a href=\"/title/tt5500218/?ref_=rlm\">Samaritan</a>,\n",
       " <a href=\"/title/tt10245072/?ref_=rlm\">Salem's Lot</a>,\n",
       " <a href=\"/title/tt9204328/?ref_=rlm\">Dark Harvest</a>,\n",
       " <a href=\"/title/tt10731256/?ref_=rlm\">Don't Worry Darling</a>,\n",
       " <a href=\"/title/tt9603212/?ref_=rlm\">Mission: Impossible 7</a>,\n",
       " <a href=\"/title/tt9362722/?ref_=rlm\">Spider-Man: Into the Spider-Verse 2</a>,\n",
       " <a href=\"/title/tt10665342/?ref_=rlm\">Halloween Ends</a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# достать ссылки можно так, но как понять, к какой дате они относятся??\n",
    "soup.find_all('a', attrs = {'href' : re.compile('title/tt')}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем по-другому\n",
    "info = soup.find_all('div', {'id': 'main'})[0].find_all('ul')\n",
    "#info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь количество дат соответствует количеству элементов полученного выше списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul>\n",
       "<li>\n",
       "<a href=\"/title/tt12335692/?ref_=rlm\">Last Man Down</a> (2021)\n",
       "                        </li>\n",
       "</ul>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/title/tt12335692/?ref_=rlm\">Last Man Down</a>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0].find_all('a')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/title/tt12335692/?ref_=rlm'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www.imdb.com' + info[0].find_all('a')[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt12335692/?ref_=rlm']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://www.imdb.com' + i.get('href') for i in info[0].find_all('a')]\n",
    "urls # это ссылки на все фильмы соответствующей даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Last Man Down'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0].find_all('a')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last Man Down']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [i.text for i in info[0].find_all('a')]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = {}\n",
    "for d in range(len(dates)):\n",
    "    \n",
    "    names = [i.text for i in info[d].find_all('a')]\n",
    "    urls = ['https://www.imdb.com' + i.get('href') for i in info[d].find_all('a')]\n",
    "    \n",
    "    urls_names = {}\n",
    "    for x in range(len(names)):\n",
    "        urls_names[names[x]] = [urls[x]] # ключом словаря будет дата, а значением — ссылка\n",
    "    \n",
    "    movies[dates[d].text] = urls_names\n",
    "#movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eternals</th>\n",
       "      <th>Spencer</th>\n",
       "      <th>Ida Red</th>\n",
       "      <th>Violet</th>\n",
       "      <th>The Beta Test</th>\n",
       "      <th>Dangerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ссылка</th>\n",
       "      <td>https://www.imdb.com/title/tt9032400/?ref_=rlm</td>\n",
       "      <td>https://www.imdb.com/title/tt12536294/?ref_=rlm</td>\n",
       "      <td>https://www.imdb.com/title/tt11388416/?ref_=rlm</td>\n",
       "      <td>https://www.imdb.com/title/tt6852672/?ref_=rlm</td>\n",
       "      <td>https://www.imdb.com/title/tt11738830/?ref_=rlm</td>\n",
       "      <td>https://www.imdb.com/title/tt3876910/?ref_=rlm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Eternals  \\\n",
       "Ссылка  https://www.imdb.com/title/tt9032400/?ref_=rlm   \n",
       "\n",
       "                                                Spencer  \\\n",
       "Ссылка  https://www.imdb.com/title/tt12536294/?ref_=rlm   \n",
       "\n",
       "                                                Ida Red  \\\n",
       "Ссылка  https://www.imdb.com/title/tt11388416/?ref_=rlm   \n",
       "\n",
       "                                                Violet  \\\n",
       "Ссылка  https://www.imdb.com/title/tt6852672/?ref_=rlm   \n",
       "\n",
       "                                          The Beta Test  \\\n",
       "Ссылка  https://www.imdb.com/title/tt11738830/?ref_=rlm   \n",
       "\n",
       "                                             Dangerous  \n",
       "Ссылка  https://www.imdb.com/title/tt3876910/?ref_=rlm  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = ['Ссылка']\n",
    "df = pd.DataFrame(movies['05 November 2021'], index = rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [['05 November 2021']*len(movies['05 November 2021'].keys()),\n",
    "                            list(movies['05 November 2021'].keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Соберите информацию о сотрудниках [кафедры высшей математики](https://hmat.hse.ru/persons). Если сотрудник ведет какие-то курсы, то также название курса и ссылка на его страницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://hmat.hse.ru/persons'\n",
    "page = requests.get(url)\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = soup.find_all('div', {'class': 'fa-person__box'})\n",
    "#info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = info[14].find('a').text.strip()\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = info[14].find('p').text.strip()\n",
    "degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_person = 'https:' + info[14].find('a').get('href')\n",
    "url_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = 'https://www.hse.ru/org/persons/207912918'\n",
    "url0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page0 = requests.get(url0)\n",
    "page0.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup0 = BeautifulSoup(page0.text)\n",
    "#soup0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = soup0.find_all('div', {'tab-node':'edu-courses'})\n",
    "courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_info = courses[0].find_all('a', {'class':'link'})\n",
    "courses_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff = {}\n",
    "\n",
    "for i in info:\n",
    "    name = i.find('a').text.strip()\n",
    "    degree = i.find('p').text.strip()\n",
    "    url_person = 'https:' + i.find('a').get('href')\n",
    "    \n",
    "    page0 = requests.get(url_person)\n",
    "    soup0 = BeautifulSoup(page0.text)\n",
    "    \n",
    "    sleep(1)\n",
    "    \n",
    "    courses = soup0.find_all('div', {'tab-node':'edu-courses'})\n",
    "    if len(courses) != 0:\n",
    "        courses_info = courses[0].find_all('a', {'class':'link'})\n",
    "\n",
    "        empty_dict = {}\n",
    "\n",
    "        for i in range(0, len(courses_info), 2):\n",
    "\n",
    "            key = courses_info[i].get('href')\n",
    "            value_name = courses_info[i].text\n",
    "            value_fac = courses_info[i+1].text\n",
    "\n",
    "            empty_dict[key] = [value_name, value_fac]\n",
    "\n",
    "        staff[f'{name}({degree})'] = empty_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['Название', 'Факультет']\n",
    "df = pd.DataFrame(staff[list(staff.keys())[0]], index = rows)\n",
    "\n",
    "df.columns = [[list(staff.keys())[0]]*len(staff[list(staff.keys())[0]].keys()),\n",
    "                            list(staff[list(staff.keys())[0]].keys())]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(staff.keys())[1:]:\n",
    "    df_to_join = pd.DataFrame(staff[i], index = rows)\n",
    "    df_to_join.columns = [[i]*len(staff[i].keys()),\n",
    "                            list(staff[i].keys())]\n",
    "    \n",
    "    df = df.join(df_to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Дана ссылка на первую страницу [каталога книжных новинок](https://www.bgshop.ru/catalog/group?id=444&page=1&sort=1&instock=). Соберите информацию о книгах с первых трех страниц. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for i in range(1,4):\n",
    "    urls.append(f'https://www.bgshop.ru/catalog/group?id=444&page={i}&sort=1&instock=')\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(urls[0])\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = soup.find_all('div', {'class':'product'})[0]\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ссылка\n",
    "url0 = 'https://www.bgshop.ru/' + product.find_all('a')[0].get('href')\n",
    "url0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page0 = requests.get(url0)\n",
    "soup0 = BeautifulSoup(page0.text)\n",
    "#soup0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_info = soup0.find_all('div', {'id':'productMain'})[0]\n",
    "main_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = main_info.find_all('p')[0].text\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = main_info.find_all('h1')[0].text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = main_info.find_all('p', {'class':'item-status'})[0].text\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = main_info.find_all('div', {'id':'price'})[0].text\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_clean = float(re.findall(r'\\d+,\\d+', price)[0].replace(',', '.'))\n",
    "price_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {}\n",
    "\n",
    "for i in soup.find_all('div', {'class':'product'}):\n",
    "    url0 = 'https://www.bgshop.ru/' + i.find_all('a')[0].get('href')\n",
    "    page0 = requests.get(url0)\n",
    "    soup0 = BeautifulSoup(page0.text)\n",
    "    sleep(1)\n",
    "    \n",
    "    main_info = soup0.find_all('div', {'id':'productMain'})[0]\n",
    "    author = main_info.find_all('p')[0].text\n",
    "    title = main_info.find_all('h1')[0].text\n",
    "    status = main_info.find_all('p', {'class':'item-status'})[0].text\n",
    "    \n",
    "    price = main_info.find_all('div', {'id':'price'})[0].text\n",
    "    price_clean = float(re.findall(r'\\d+,\\d+', price)[0].replace(',', '.'))\n",
    "    \n",
    "    books[title] = [author, status, price_clean, url0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь для всех (трех) страниц с книгами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {}\n",
    "for u in urls:\n",
    "    page = requests.get(u)\n",
    "    soup = BeautifulSoup(page.text)\n",
    "    sleep(1)\n",
    "    info = soup.find_all('div', {'class':'product'})\n",
    "    for i in info:\n",
    "        url0 = 'https://www.bgshop.ru/' + i.find_all('a')[0].get('href')\n",
    "        page0 = requests.get(url0)\n",
    "        soup0 = BeautifulSoup(page0.text)\n",
    "        sleep(1)\n",
    "\n",
    "        main_info = soup0.find_all('div', {'id':'productMain'})[0]\n",
    "        author = main_info.find_all('p')[0].text\n",
    "        title = main_info.find_all('h1')[0].text\n",
    "        status = main_info.find_all('p', {'class':'item-status'})[0].text\n",
    "\n",
    "        price = main_info.find_all('div', {'id':'price'})[0].text\n",
    "        price_change = float(re.findall(r'\\d+,\\d+', price)[0].replace(',', '.'))\n",
    "\n",
    "        books[title] = [author, status, price_change, url0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(books, index = ['Автор', 'Статус', 'Цена', 'Ссылка']).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Дана ссылка на [сайт газеты \"Московский комсомолец\"](https://www.mk.ru/news/). Соберите ссылки на новости первой страницы, время публикации, заголовок. Пройдите по ссылкам и соберите количество просмотров и хэштеги статьи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mk.ru/news/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('li', {'class':'news-listing__item'})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = soup.find_all('li', {'class':'news-listing__item'})[0].find('a').get('href')\n",
    "url0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = soup.find_all('li', {'class':'news-listing__item'})[0].find('span').text\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find_all('li', {'class':'news-listing__item'})[0].find('h3').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page0 = requests.get(url0)\n",
    "soup0 = BeautifulSoup(page0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup0.find_all('span', {'class':'meta__item_views'})[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup0.find('div', {'class':'article__tag'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'[^\\n]+', soup0.find('div', {'class':'article__tag'}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = {}\n",
    "for i in soup.find_all('li', {'class':'news-listing__item'}):\n",
    "    url0 = i.find('a').get('href')\n",
    "    time = i.find('span').text\n",
    "    title = i.find('h3').text\n",
    "    \n",
    "    page0 = requests.get(url0)\n",
    "    soup0 = BeautifulSoup(page0.text)\n",
    "    sleep(1)\n",
    "    \n",
    "    view = int(soup0.find_all('span', {'class':'meta__item_views'})[0].text.strip())\n",
    "    \n",
    "    if soup0.find('div', {'class':'article__tag'}) is None:\n",
    "        tags = ''\n",
    "    else:\n",
    "        tags = ', '.join(re.findall(r'[^\\n]+', soup0.find('div', {'class':'article__tag'}).text))\n",
    "        \n",
    "    news[title] = [url0, time, view, tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно также сразу указывать, что у нас данные из словаря, orient='index' вместо transpose()\n",
    "df = pd.DataFrame.from_dict(news, orient='index', columns = ['Ссылка','Время','Просмотры','Теги'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
